{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_dev = pd.read_csv('data/development.csv').set_index('Id')\n",
    "df_eval = pd.read_csv('data/evaluation.csv').set_index('Id')\n",
    "\n",
    "# We drop the sampling rate, which is the same value for all samples\n",
    "# We drop the path, which is not useful for the regression task\n",
    "df_dev.drop(['sampling_rate', 'path'], axis=1, inplace=True)\n",
    "df_eval.drop(['sampling_rate', 'path'], axis=1, inplace=True)\n",
    "\n",
    "# We convert the tempo to the float data type from the format '[float]'\n",
    "df_dev['tempo'] = df_dev['tempo'].apply(lambda x: x.replace('[', '').replace(']', '')).astype('float')\n",
    "df_eval['tempo'] = df_eval['tempo'].apply(lambda x: x.replace('[', '').replace(']', '')).astype('float')\n",
    "\n",
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot age distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(df_dev[\"age\"], bins=range(0,int((max(df_dev[\"age\"])+10)),10))\n",
    "ax.set_xticks(range(0,int((max(df_dev[\"age\"])+10)),10))\n",
    "ax.set_title(\"Age Distribution\")\n",
    "ax.set_xlabel(\"Age\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.grid(alpha=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ethnicity distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ethnicities in development set\n",
    "set1 = set(df_dev[\"ethnicity\"])\n",
    "set2 = set(df_eval[\"ethnicity\"])\n",
    "set1.intersection(set2)\n",
    "print(f\"Number of ethnicities in development set: {len(set1)}\")\n",
    "print(f\"Number of ethnicities in evaluation set: {len(set2)}\")\n",
    "print(f\"Number of ethnicities in both sets: {len(set1.intersection(set2))}\")\n",
    "print(set1.intersection(set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev.drop(columns=['ethnicity'], inplace=True)\n",
    "df_eval.drop(columns=['ethnicity'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender =  {'male': 1, 'female': 0, \"famale\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "gender_dev = Counter(df_dev[\"gender\"])\n",
    "gender_eval = Counter(df_eval[\"gender\"])\n",
    "plt.figure()\n",
    "plt.bar(gender_dev.keys(), gender_dev.values(), label=\"Development\", color=\"orange\", alpha=0.5)\n",
    "plt.bar(gender_eval.keys(), gender_eval.values(), label=\"Evaluation\", color=\"blue\", alpha=0.5)\n",
    "plt.title(\"Gender Distribution\")\n",
    "plt.xlabel(\"Gender\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.2, axis=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We encode the gender using dummy encoding\n",
    "df_dev['gender'] = df_dev['gender'].map(gender)\n",
    "df_eval['gender'] = df_eval['gender'].map(gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "\n",
    "mfcc_num = 13\n",
    "ll = []\n",
    "for f in os.listdir(\"data/audios_development\"):\n",
    "    try:\n",
    "        y, sr = librosa.load(f\"data/audios_development/{f}\", sr=None)\n",
    "        index = int(f.split(\".\")[0]) - 1\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        duration = librosa.get_duration(y=y, sr=sr)\n",
    "        mfdd = librosa.feature.delta(mfcc)\n",
    "        mfddd = librosa.feature.delta(mfcc, order=2)\n",
    "        spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr).mean(axis=1)\n",
    "        spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr).mean(axis=1)\n",
    "\n",
    "        d = {f\"MFCC-{el+1}-95\": np.percentile(mfcc, 95, axis=1)[el] for el in range(mfcc_num)}\n",
    "        d |= {f\"MFCC-{el+1}-5\": np.percentile(mfcc, 5, axis=1)[el] for el in range(mfcc_num)}\n",
    "        d |= {f\"MFCC-{el+1}-50\": np.percentile(mfcc, 50, axis=1)[el] for el in range(mfcc_num)}\n",
    "        d |= {f\"MFCCD-{el+1}-95\": np.percentile(mfdd, 95, axis=1)[el] for el in range(mfcc_num)}\n",
    "        d |= {f\"MFCCD-{el+1}-5\": np.percentile(mfdd, 5, axis=1)[el] for el in range(mfcc_num)}\n",
    "        d |= {f\"MFCCD-{el+1}-50\": np.percentile(mfdd, 50, axis=1)[el] for el in range(mfcc_num)}\n",
    "        d |= {f\"MFCCDD-{el+1}-95\": np.percentile(mfddd, 95, axis=1)[el] for el in range(mfcc_num)}\n",
    "        d |= {f\"MFCCDD-{el+1}-5\": np.percentile(mfddd, 5, axis=1)[el] for el in range(mfcc_num)}\n",
    "        d |= {f\"MFCCDD-{el+1}-50\": np.percentile(mfddd, 50, axis=1)[el] for el in range(mfcc_num)}\n",
    "        ll.append({'Id': index, \"duration\": duration, \"spectral_bandwidth\": spectral_bandwidth, \"spectral_rolloff\": spectral_rolloff, **d})\n",
    "    except:\n",
    "        pass\n",
    "df1 = pd.DataFrame(ll).set_index('Id').sort_index()\n",
    "\n",
    "ll = []\n",
    "for f in os.listdir(\"data/audios_evaluation\"):\n",
    "    try:\n",
    "        y, sr = librosa.load(f\"data/audios_evaluation/{f}\", sr=None)\n",
    "        index = int(f.split(\".\")[0]) - 1\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        duration = librosa.get_duration(y=y, sr=sr)\n",
    "        mfdd = librosa.feature.delta(mfcc)\n",
    "        mfddd = librosa.feature.delta(mfcc, order=2)\n",
    "        spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr).mean(axis=1)\n",
    "        spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr).mean(axis=1)\n",
    "\n",
    "        d = {f\"MFCC-{el+1}-95\": np.percentile(mfcc, 95, axis=1)[el] for el in range(mfcc_num)}\n",
    "        d |= {f\"MFCC-{el+1}-5\": np.percentile(mfcc, 5, axis=1)[el] for el in range(mfcc_num)}\n",
    "        d |= {f\"MFCC-{el+1}-50\": np.percentile(mfcc, 50, axis=1)[el] for el in range(mfcc_num)}\n",
    "        d |= {f\"MFCCD-{el+1}-95\": np.percentile(mfdd, 95, axis=1)[el] for el in range(mfcc_num)}\n",
    "        d |= {f\"MFCCD-{el+1}-5\": np.percentile(mfdd, 5, axis=1)[el] for el in range(mfcc_num)}\n",
    "        d |= {f\"MFCCD-{el+1}-50\": np.percentile(mfdd, 50, axis=1)[el] for el in range(mfcc_num)}\n",
    "        d |= {f\"MFCCDD-{el+1}-95\": np.percentile(mfddd, 95, axis=1)[el] for el in range(mfcc_num)}\n",
    "        d |= {f\"MFCCDD-{el+1}-5\": np.percentile(mfddd, 5, axis=1)[el] for el in range(mfcc_num)}\n",
    "        d |= {f\"MFCCDD-{el+1}-50\": np.percentile(mfddd, 50, axis=1)[el] for el in range(mfcc_num)}\n",
    "        ll.append({'Id': index, \"duration\": duration, \"spectral_bandwidth\": spectral_bandwidth, \"spectral_rolloff\": spectral_rolloff, **d})\n",
    "    except:\n",
    "        pass\n",
    "df2 = pd.DataFrame(ll).set_index('Id').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev = pd.concat([df_dev, df1], axis=1)\n",
    "df_eval = pd.concat([df_eval, df2], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Num words and num characters distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(df_dev[\"num_words\"], bins=range(0,int((max(df_dev[\"num_words\"])+10)),10), label=\"Development\", color=\"orange\", alpha=0.5)\n",
    "plt.hist(df_eval[\"num_words\"], bins=range(0,int((max(df_eval[\"num_words\"])+10)),10), label=\"Evaluation\", color=\"blue\", alpha=0.5)\n",
    "plt.xticks(range(0,int((max(df_dev[\"num_words\"])+10)),10))\n",
    "plt.title(\"Distribution of the number of words\")\n",
    "plt.xlabel(\"Number of words\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(df_dev[\"num_characters\"], bins=range(0,int((max(df_dev[\"num_characters\"])+20)),20), label=\"Development\", color=\"orange\", alpha=0.5)\n",
    "plt.hist(df_eval[\"num_characters\"], bins=range(0,int((max(df_eval[\"num_characters\"])+20)),20), label=\"Evaluation\", color=\"blue\", alpha=0.5)\n",
    "plt.xticks(range(0,int((max(df_dev[\"num_characters\"])+20)),20))\n",
    "plt.title(\"Distribution of the number of characters\")\n",
    "plt.xlabel(\"Number of characters\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev['mean_silence'] = df_dev['silence_duration']/df_dev['num_pauses']\n",
    "df_dev['silence_ratio'] = df_dev['silence_duration']/df_dev['duration']\n",
    "df_dev['wps'] = df_dev['num_words']/df_dev['duration']\n",
    "\n",
    "df_eval['mean_silence'] = df_eval['silence_duration']/df_eval['num_pauses']\n",
    "df_eval['silence_ratio'] = df_eval['silence_duration']/df_eval['duration']\n",
    "df_eval['wps'] = df_eval['num_words']/df_eval['duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev['spectral_bandwidth'] = df_dev['spectral_bandwidth'].apply(lambda x: str(x[0]).replace('[', '').replace(']', '')).astype('float')\n",
    "df_eval['spectral_bandwidth'] = df_eval['spectral_bandwidth'].apply(lambda x: str(x[0]).replace('[', '').replace(']', '')).astype('float')\n",
    "\n",
    "df_dev['spectral_rolloff'] = df_dev['spectral_rolloff'].apply(lambda x: str(x[0]).replace('[', '').replace(']', '')).astype('float')\n",
    "df_eval['spectral_rolloff'] = df_eval['spectral_rolloff'].apply(lambda x: str(x[0]).replace('[', '').replace(']', '')).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev.to_csv('data/development_processed.csv')\n",
    "df_eval.to_csv('data/evaluation_processed.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScienceLabLabs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
