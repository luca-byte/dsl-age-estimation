{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_dev = pd.read_csv('data/development.csv').set_index('Id')\n",
    "df_eval = pd.read_csv('data/evaluation.csv').set_index('Id')\n",
    "\n",
    "df_dev.drop(['sampling_rate', 'path'], axis=1, inplace=True)\n",
    "df_eval.drop(['sampling_rate', 'path'], axis=1, inplace=True)\n",
    "\n",
    "df_dev['tempo'] = df_dev['tempo'].apply(lambda x: x.replace('[', '').replace(']', '')).astype('float')\n",
    "df_eval['tempo'] = df_eval['tempo'].apply(lambda x: x.replace('[', '').replace(']', '')).astype('float')\n",
    "df_dev['tempo'].dtype, df_eval['tempo'].dtype\n",
    "\n",
    "df_dev.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "print(Counter(df_dev[\"gender\"]))\n",
    "print(Counter(df_eval[\"gender\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev = df_dev[df_dev[\"age\"]<=70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "temp = Counter(df_dev[\"age\"])\n",
    "print(temp)\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(temp.keys(), temp.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_dev['gender'].value_counts())\n",
    "print(df_eval['gender'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender =  {'male': 1, 'female': 0, \"famale\": 0}\n",
    "\n",
    "# We encode the gender using dummy encoding\n",
    "df_dev['gender'] = df_dev['gender'].map(gender)\n",
    "df_eval['gender'] = df_eval['gender'].map(gender)\n",
    "print(df_dev['gender'].value_counts())\n",
    "print(df_eval['gender'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set1 = set(df_dev[\"ethnicity\"])\n",
    "set2 = set(df_eval[\"ethnicity\"])\n",
    "set1.intersection(set2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "temp = defaultdict(lambda: 0)\n",
    "for el in df_eval[\"ethnicity\"]:\n",
    "    if el in set1.intersection(set2):\n",
    "        temp[el] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We keep only the `igbo` ethicity since it is the only ethnicity which is significantly present\n",
    "# in both the development and the evaluation dataset\n",
    "\n",
    "df_dev['igbo'] = df_dev['ethnicity'].apply(lambda z: 1 if z == 'igbo' else 0)\n",
    "df_dev.drop('ethnicity', axis=1, inplace=True)\n",
    "\n",
    "df_eval['igbo'] = df_eval['ethnicity'].apply(lambda z: 1 if z == 'igbo' else 0)\n",
    "df_eval.drop('ethnicity', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We apply the log function to obtain a greater spread of values. \n",
    "df_dev['energy'] = df_dev['energy'].apply(np.log)\n",
    "df_eval['energy'] = df_eval['energy'].apply(np.log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev.drop([\"max_pitch\",\"mean_pitch\"], axis='columns', inplace=True)\n",
    "df_eval.drop([\"max_pitch\", \"mean_pitch\"], axis=\"columns\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev['jitter'] = df_dev['jitter'].apply(np.log)\n",
    "df_eval['jitter'] = df_eval['jitter'].apply(np.log)\n",
    "\n",
    "df_dev['shimmer'] = df_dev['shimmer'].apply(np.log)\n",
    "df_eval['shimmer'] = df_eval['shimmer'].apply(np.log)\n",
    "\n",
    "df_dev['min_pitch'] = df_dev['min_pitch'].apply(np.log)\n",
    "df_eval['min_pitch'] = df_eval['min_pitch'].apply(np.log)\n",
    "\n",
    "df_dev['zcr_mean'] = df_dev['zcr_mean'].apply(np.log)\n",
    "df_eval['zcr_mean'] = df_eval['zcr_mean'].apply(np.log)\n",
    "\n",
    "df_dev['spectral_centroid_mean'] = df_dev['spectral_centroid_mean'].apply(np.log)\n",
    "df_eval['spectral_centroid_mean'] = df_eval['spectral_centroid_mean'].apply(np.log)\n",
    "\n",
    "df_dev['tempo'] = df_dev['tempo'].apply(np.log)\n",
    "df_eval['tempo'] = df_eval['tempo'].apply(np.log)\n",
    "\n",
    "df_dev['num_pauses'] = df_dev['num_pauses'].apply(np.log)\n",
    "df_eval['num_pauses'] = df_eval['num_pauses'].apply(np.log)\n",
    "\n",
    "df_dev['silence_duration'] = df_dev['silence_duration'].apply(np.log)\n",
    "df_eval['silence_duration'] = df_eval['silence_duration'].apply(np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev.drop([\"num_words\",\"min_pitch\",\"shimmer\", \"energy\"], axis='columns', inplace=True)\n",
    "df_eval.drop([\"num_words\",\"min_pitch\",\"shimmer\", \"energy\"], axis=\"columns\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "y_dev = df_dev[\"age\"]\n",
    "X_dev = df_dev.drop(columns=[\"age\"])\n",
    "X_dev.head()\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_dev, y_dev, random_state=0, test_size=0.2)\n",
    "X_test = df_eval\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_val = ss.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "sns.heatmap(X_dev.corr(), cmap=\"crest\", annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = RandomForestRegressor(random_state=0, n_jobs=-1, criterion=\"squared_error\", n_estimators=200) #Â squared error since if small also RMSE is small\n",
    "\n",
    "reg.fit(X_train,y_train)\n",
    "\n",
    "y_pred = reg.predict(X_val)\n",
    "\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "root_mean_squared_error(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR \n",
    "from sklearn.tree import DecisionTreeRegressor  \n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "for model in [LinearRegression, Lasso, Ridge, RandomForestRegressor, SVR, DecisionTreeRegressor, KNeighborsRegressor, MLPRegressor]:\n",
    "    reg = model()\n",
    "    reg.fit(X_train, y_train)\n",
    "    y_pred = reg.predict(X_val)\n",
    "    rmse = root_mean_squared_error(y_val, y_pred)\n",
    "    print(f'{model.__name__} RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "polynomial = PolynomialFeatures(2)\n",
    "X_train = polynomial.fit_transform(X_train)\n",
    "# reg = LinearRegression()\n",
    "reg = Ridge(alpha=35)\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(polynomial.transform(X_val))\n",
    "# y_pred = reg.predict(X_val)\n",
    "rmse = root_mean_squared_error(y_val, y_pred)\n",
    "print(f'RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import QuantileRegressor\n",
    "\n",
    "y_dev = df_dev[\"age\"]\n",
    "X_dev = df_dev.drop(columns=[\"age\"])\n",
    "X_test = df_eval\n",
    "\n",
    "ss = StandardScaler()\n",
    "# ss = MinMaxScaler()\n",
    "X_dev = ss.fit_transform(X_dev)\n",
    "X_test = ss.transform(X_test)\n",
    "\n",
    "polynomial = PolynomialFeatures(2)\n",
    "X_dev = polynomial.fit_transform(X_dev)\n",
    "X_test = polynomial.transform(X_test)\n",
    "\n",
    "# reg = LinearRegression()\n",
    "reg = Ridge()\n",
    "\n",
    "grid = {\n",
    "    \"alpha\": list(range(1,200,4)),\n",
    "    # \"n_estimators\": [100,200,250,300]\n",
    "}\n",
    "gridSearch = GridSearchCV(reg, grid, n_jobs=-1, verbose=6, cv=20, scoring=\"neg_root_mean_squared_error\")\n",
    "gridSearch.fit(X_dev, y_dev)\n",
    "reg = gridSearch.best_estimator_\n",
    "print(gridSearch.best_estimator_)\n",
    "print(gridSearch.best_params_)\n",
    "print(gridSearch.best_score_)\n",
    "\n",
    "# reg = Ridge(1)\n",
    "# reg.fit(X_dev, y_dev)\n",
    "y_pred = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_pred<0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataFrameOutput = pd.DataFrame({\"Predicted\": np.round(y_pred,2)})\n",
    "\n",
    "dataFrameOutput.index.name = \"Id\"\n",
    "dataFrameOutput.to_csv(\"./data/output.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScienceLabLabs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
